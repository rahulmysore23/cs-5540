{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKWX9c6jyaBX",
        "outputId": "528888c7-b92d-4f7c-eed8-bd9c88cd891b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425345 sha256=bb8f0ca15d31578894fec6150841e9944693018ec47f55d6c917669a9b186d78\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n",
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install findspark\n",
        "!pip install pandas\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loAE0MjG4LzB",
        "outputId": "0916f446-38fa-4a45-a7bb-eb864fa87556"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fu366OT_4Tvm",
        "outputId": "61628ef9-e06a-4959-a0ea-53ff874d7719"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing values:\n",
            "name                              0\n",
            "stars                             0\n",
            "forks                             0\n",
            "watchers                          0\n",
            "pullRequests                      0\n",
            "primaryLanguage                   0\n",
            "defaultBranchCommitCount          2\n",
            "createdAt                         0\n",
            "license                     1378490\n",
            "dtype: int64\n",
            "Number of rows in the DataFrame: 3021631\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file into a pandas DataFrame\n",
        "file_path = './dataset/filtered_output.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Display information about missing values\n",
        "print(\"Missing values:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "num_rows = len(data)\n",
        "print(\"Number of rows in the DataFrame:\", num_rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCFmNVO34wid",
        "outputId": "b414947e-be00-4fc7-bbdc-e5b4ee3c016c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the model (after cross-validation): 67.01%\n",
            "Accuracy of the model (after stratified cross-validation): 82.10%\n",
            "Precision: 0.83\n",
            "Recall: 0.82\n",
            "F1 Score: 0.79\n",
            "\n",
            "Top Languages That Might Become Popular in Future:\n",
            "TypeScript\n",
            "Nix\n",
            "Rust\n",
            "Batchfile\n",
            "PLpgSQL\n",
            "Go\n",
            "SCSS\n",
            "Kotlin\n",
            "HTML\n",
            "Jupyter Notebook\n",
            "\n",
            "Top Languages That Might Become Extinct:\n",
            "Ragel in Ruby Host\n",
            "Gradle\n",
            "desktop\n",
            "Quake\n",
            "WGSL\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "from matplotlib.ticker import FuncFormatter\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Filter columns for modeling\n",
        "selected_columns = ['name', 'stars', 'forks', 'watchers', 'pullRequests', 'primaryLanguage', 'defaultBranchCommitCount', 'createdAt', 'license']\n",
        "model_data = data[selected_columns].copy()  # Make a copy to avoid SettingWithCopyWarning\n",
        "\n",
        "# Convert 'createdAt' to datetime explicitly\n",
        "data['createdAt'] = pd.to_datetime(data['createdAt'])\n",
        "\n",
        "# Extract year from the 'createdAt' column using .dt accessor\n",
        "data['year'] = data['createdAt'].dt.year\n",
        "\n",
        "# Filter columns for modeling\n",
        "selected_columns = ['name', 'primaryLanguage', 'year']  # Include 'year' in selected columns\n",
        "model_data = data[selected_columns].copy()  # Make a copy to avoid SettingWithCopyWarning\n",
        "\n",
        "# Calculate language growth based on year\n",
        "language_growth = model_data.groupby(['primaryLanguage', 'year']).size().unstack(fill_value=0)\n",
        "\n",
        "# Define the response variable (language growth)\n",
        "language_growth['growth'] = language_growth.diff(axis=1).fillna(0).apply(lambda x: x.gt(0).sum(), axis=1)\n",
        "\n",
        "# Reset index to make 'primary_language' a column\n",
        "language_growth.reset_index(inplace=True)\n",
        "\n",
        "# Merge 'growth' information back to the original dataset\n",
        "model_data = pd.merge(model_data, language_growth[['primaryLanguage', 'growth']], on='primaryLanguage')\n",
        "\n",
        "# Encode categorical variables\n",
        "label_encoder = LabelEncoder()\n",
        "model_data['name'] = label_encoder.fit_transform(model_data['name'])\n",
        "model_data['primaryLanguage'] = label_encoder.fit_transform(model_data['primaryLanguage'])\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", message=\"The least populated class in y has only 1 members\")\n",
        "# Define features and target variable\n",
        "X = model_data[['name', 'primaryLanguage']]\n",
        "y = model_data['growth']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train a decision tree classifier with constraints\n",
        "clf = DecisionTreeClassifier(random_state=42, max_depth=5, min_samples_split=5, min_samples_leaf=4)\n",
        "\n",
        "# Perform cross-validation to assess the model's performance\n",
        "cv_scores = cross_val_score(clf, X, y, cv=5)  # Using 5-fold cross-validation\n",
        "average_accuracy = cv_scores.mean() * 100  # Calculating average accuracy in percentage\n",
        "# Suppress the specific UserWarning\n",
        "\n",
        "\n",
        "print(\"Accuracy of the model (after cross-validation): {:.2f}%\".format(average_accuracy))\n",
        "\n",
        "# Initialize StratifiedKFold for cross-validation\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform cross-validation with stratified k-fold\n",
        "cv_scores = cross_val_score(clf, X, y, cv=skf)\n",
        "average_accuracy = cv_scores.mean() * 100\n",
        "\n",
        "print(\"Accuracy of the model (after stratified cross-validation): {:.2f}%\".format(average_accuracy))\n",
        "\n",
        "# Fit the model on the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "\n",
        "# Calculate precision, recall, and F1 score with zero_division handling\n",
        "precision = precision_score(y_test, y_pred, average='weighted', zero_division=1)\n",
        "recall = recall_score(y_test, y_pred, average='weighted', zero_division=1)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=1)\n",
        "\n",
        "print(\"Precision: {:.2f}\".format(precision))\n",
        "print(\"Recall: {:.2f}\".format(recall))\n",
        "print(\"F1 Score: {:.2f}\".format(f1))\n",
        "print()\n",
        "\n",
        "# Reset the warning filters to default (if needed)\n",
        "warnings.filterwarnings(\"default\")\n",
        "\n",
        "# Filter out the top  growing languages\n",
        "top_growing_languages = language_growth.sort_values('growth', ascending=False).head(5)\n",
        "\n",
        "# Filter out the top  declining languages\n",
        "top_declining_languages = language_growth.sort_values('growth', ascending=True).head(5)\n",
        "\n",
        "# Extracting top 10 growing languages\n",
        "top_10_growing = language_growth.sort_values('growth', ascending=False).head(10)\n",
        "\n",
        "# Displaying the top 10 growing languages without growth percentages\n",
        "print(\"Top Languages That Might Become Popular in Future:\")\n",
        "for lang in top_10_growing['primaryLanguage']:\n",
        "    print(lang)\n",
        "\n",
        "# Adding a line gap\n",
        "print()\n",
        "\n",
        "# Extracting top  declining languages\n",
        "top_10_declining = language_growth.sort_values('growth', ascending=True).head(5)\n",
        "\n",
        "# Displaying the top  declining languages without growth percentages\n",
        "print(\"Top Languages That Might Become Extinct:\")\n",
        "for lang in top_10_declining['primaryLanguage']:\n",
        "    print(lang)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
